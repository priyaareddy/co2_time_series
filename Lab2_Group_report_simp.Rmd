---
title: "Global $CO_{2}$ Emissions 1995 and Present"
subtitle: "What Keeling missed all these years"
author: "Yuna Kim, Jinsoo Chung, Priya Reddy, Jocelyn Thai"
output: bookdown::pdf_document2
fontsize: 11pt
geometry: margin=1in
---

```{r load packages, echo = FALSE, message = FALSE, warning=FALSE}
#load all packages needed
library(tidyverse)
library(tsibble)
library(latex2exp)
library(lubridate)
library(patchwork)
library(magrittr)
library(tsibble)
library(feasts)
library(forecast)
library(stargazer)
library(sandwich)
library(lmtest)
library(fable)
library(MASS)

library(blsR)

library(httr)
library(jsonlite)

library(plyr)
library(dplyr)
library(tidyr)
library(fable)
library(gridExtra)


theme_set(theme_minimal())
knitr::opts_chunk$set(dpi=1000)
```


```{r setup, echo=FALSE}
## default to not show code, unless we ask for it.
knitr::opts_chunk$set(echo=FALSE)
##default to display all plots centered unless we adjust them
knitr::opts_chunk$set(fig.align='center')
##default to display 5 digits of every number
options(digits = 5)
```

# Background 

### Abstract
Understanding a changing climate, and what it means for the earth's inhabitants is of growing interest to the scientific and policy community. Although, at this point in 1997 it is not entirely clear what the consequences of this growing awareness will be, in this report we present likely outcomes under "business-as-usual" scenarios. In doing so, our hope, is to establish a series of possible futures, and, as evidence, technology, and policy develop over the coming decades, our goal is that we can theb weigh the impacts that carbon-emission reduction efforts might take. In this report we seek to understand if atmospheric CO2 levels have increased since 1997 and if we anticipate that this trend will continue. To do this we seek to answer 2 main questions:
1. What is the best model we can use to model CO2 levels over time?
2. Using this model, what do we forecast atmospheric CO2 levels will be? And how confident are we in these predictions?

### Carbon Emissions 
High CO2 levels have been shown to negatively play into climate change, and the increase in atmospheric CO2 has cascading effects from global warming to ocean acidification. Due to these effects, we may notice food supply chain disruptions, natural disasters of increasing intensity, and habitat disruption of all ecosystems and the animal species living there. In an economical sense, understanding these patterns is important so we can prepare for any shifts and uncertainties in global supply chains that might arise for these new climate patterns. In total understanding the patterns in atmospheric CO2 concentrations is important both so that we can mitigate the existing effects of this increase and prevent continuing upwards trends in CO2. In addition if our report findings are significant, the findings could persuade other governmental organizations to increase their CO2 monitoring efforts and global preparedness efforts.

### Historical Trends in Atmospheric Carbon 
In 1958 Charles Keeling began continuous monitoring of atmospheric carbon dioxide concentrations from the Mauna Loa Observatory in Hawaii and soon observed a trend increase carbon dioxide levels in addition to the seasonal cycle. He was able to attribute this trend increase to growth in global rates of fossil fuel combustion. This trend has continued to the present, and is known as the "Keeling Curve," and is plotted below. At first glance we can see in this curve both an overall upwards trend in CO2 levels as the mean seems to be increasing over time. We can also see some sort of cyclic or seasonal pattern of atmospheric CO2 fluctuations each year.

```{r plot the keeling curve, echo = FALSE,  fig.width=5.25, fig.height=3.5}
tsibble::as_tsibble(co2) %>%
  ggplot() + 
  aes(x=index, y=value) + 
  geom_line(color = 'steelblue') +
  labs(
    title = TeX(r'(Monthly Mean $CO_2$ 1959-1997)'),
    subtitle = 'The "Keeling Curve" constructed from CO2 observations from the Mauna Loa Observatory',
    x = 'Date (Month and Year)',
    y = TeX(r'($CO_2$ (parts per million))')
  )
```


```{r,  create co2 ts, echo = FALSE}
#load in the data as tsibble
co2_ts <- tsibble::as_tsibble(co2, index = index) 
colnames(co2_ts)[2] = "co2_val"

#create logged co2 tsibble
log_ts <- co2_ts %>%
  mutate(log_co2 = log(co2_val))
#co2_ts
```


```{r, yearly co2 ts, echo = FALSE}
#create a yearly co2 tsibble
#where co2 levels are averaged over a whole year
co2_yr <- setNames(aggregate(co2_ts$co2_val, by=list(year(co2_ts$index)), mean), 
                      c("year", "yr_co2"))
#head(co2_yr)
```

Looking at the data there are three areas of interest that we may want to look into further -- the upwards trend, the seasonality, and the irregularities we observe in the data. 

To begin with we can look at the trend in our data. To better visualize the trend we can plot the yearly average CO2 level (thereby eliminating the seasonality we observed in our initial plot) over time. 

```{r, co2 ts yearly trend plot, echo = FALSE,  fig.width=5.25, fig.height=3.5}
#plot the yearly trend in co2
p6 <- co2_yr %>% 
  ggplot(aes(x = year, y = yr_co2)) + 
  geom_line() + 
  labs(title = TeX(r'(Figure 1. $CO_2$ Annual Average'),
     y = TeX(r'($CO_2$ (ppm))'),
     x = "Year")

```
We can see in Figure 1, that when we aggregate by year, there is a clearly year-over-year upwards trend in the $CO_2$ levels in the data. The lack of seasonality in this graph also indicates that our previous assumption that the seasonality was yearly is correct. 

This seasonality can be better visualized by plotting CO2 levels for each year that we have observations in our dataset.
```{r seasonality plot,warning=FALSE, fig.width=5.25, fig.height=3.5}
p2 <-co2_ts %>%
  gg_season(co2_val, labels = "right") +
  labs(y = "CO2 (ppm)", x = "Month",
       title = "Figure 2. Seasonal plot")

(p6 + p2 )
```

Figure 2 shows a clear seasonal pattern in our data. It appears as though CO2 levels peak at around May and then dip to a minimum in September and October. To further explore our initial observations on seasonality we can look at our ACF, PACF, and Lag plots.

```{r EDA ,  echo = FALSE, message=FALSE}
#inital EDA, look at  ACF, pacf, distribution, lag

p3 <- ggAcf(co2_ts$co2_val, lag.max = 48, type = 'correlation') + 
  labs(title = 'Fig 3A. ACF of Monthly CO2')

p4 <- ggAcf(co2_ts$co2_val, type = 'partial', lag.max = 48)+ 
  labs(title = 'Fig 3B.PACF of Monthly CO2')

p5 <- co2_ts%>%
  ggplot(aes(x=co2_val, y= ..count..))+
  geom_histogram()

p6 <- co2_ts %>%
  gg_lag(co2_val, geom = "point", lag=1:12) +
  labs(title = "Fig 3C. CO2 Lagged scatterplots",
       y = "CO2 (ppm)",x = "lag(Total, k)")+
  theme(axis.text.x = element_text(size = 6,angle = 45, hjust = 1))


(p3/p4) |p6

```

In Figure 3C, the lag plot, there is a very strong positive correlation across all lags, reflecting the seasonality of our data.This is also reflected in the ACF plot, Figure 3A, which decays gradually indicating a trend in our data, annd also has a subtle rise in correlation at around every 12th lag. This behavior in the ACF plot indicates a seasonal or cyclic pattern in our data. The Figure 3B PACF cuts off to zero after lag 2 and stays that way. However, at lags 12 and 13, the values become significant again. This suggests that although the model exhibits AR model-like behavior, there's some deviances in the data.

In looking at the patterns in our data we are also interested in assessing whether the upwards trend we observed is accelerating -- that is we want to look at the trend of the growth rate of CO2 levels. At a high level, knowing this could help researchers assess the efficacy of global efforts to curb CO2 emissions.

# Models and Forecasts 
In this section, we evaluate two classes of models for answering our questions -- a linear time model and and an ARIMA model to assess which time series model is most appropriate to use to model CO2 levels over time. 

## Linear Models 

To fit linear time trend model to the `co2` series we will compare a regular time trend linear model to a quadratic time trend model. We will also fit a polynomial time trend model that incorporates seasonal dummy variables, and use this model to generate forecasts to the year 2020. Note that we will be evaluating using both the unscaled CO2 and the log(CO2) value for constructing our models.  

To begin our analysis, we fit a linear model of the form to our data: 

\begin{equation}
\label{eq:one}
\text{CO}_{2} = \phi_{0} + \phi_{1} + \epsilon_{eit}
\end{equation} 

```{r, echo= FALSE, warning=FALSE}
#Linear models (original scale)
lin_model <- co2_ts%>% model(trend_model = TSLM(co2_val ~ trend()))
quad_model <- co2_ts%>%  model(trend_model = TSLM(co2_val ~ trend() + I(trend()^2 )))

#linear models (Logged CO2 values)
log_lin_model <- log_ts%>%model(trend_model = TSLM(log_co2 ~ trend() ))
log_quad_model <- log_ts%>% model(trend_model = TSLM(log_co2 ~ trend() + I(trend()^2 )))

#Polynomial model with seasonal dummy (original scale) 
quadratic_season <- co2_ts %>%
  model(trend_model = TSLM(co2_val ~ trend()+I(trend()^2)+ season())) 

#Polynomial model with seasonal dummy (Logged CO2 values)
log_quadratic_season <- log_ts %>%
  model(trend_model = TSLM(log_co2 ~ trend()+I(trend()^2)+ season())) 
```


```{r plot models against data, echo=FALSE}
p37 <- augment(lin_model)%>%
  ggplot(aes(x = index)) +
  geom_line(aes(y = co2_val, colour = "Data")) +
  geom_line(aes(y = .fitted, colour = "Fitted")) +
  labs(y = "Time",
       title = "linear model") 

p38<-augment(quad_model)%>%
  ggplot(aes(x = index)) +
  geom_line(aes(y = co2_val, colour = "Data")) +
  geom_line(aes(y = .fitted, colour = "Fitted")) +
  labs(y = "Time",
       title = "quadratic model")

p39<-augment(log_lin_model)%>%
  ggplot(aes(x = index)) +
  geom_line(aes(y = log_co2, colour = "Data")) +
  geom_line(aes(y = .fitted, colour = "Fitted")) +
  labs(y = "Time",
       title = "linear log model") 

p40<-augment(log_quad_model)%>%
  ggplot(aes(x = index)) +
  geom_line(aes(y = log_co2, colour = "Data")) +
  geom_line(aes(y = .fitted, colour = "Fitted")) +
  labs(y = "Time",
       title = "log quadratic model") 

p41<-augment(quadratic_season)%>%
  ggplot(aes(x = index)) +
  geom_line(aes(y = co2_val, colour = "Data")) +
  geom_line(aes(y = .fitted, colour = "Fitted")) +
  labs(y = "Time",
       title = "seasonal quadratic model") 

p42<-augment(log_quadratic_season)%>%
  ggplot(aes(x = index)) +
  geom_line(aes(y = log_co2, colour = "Data")) +
  geom_line(aes(y = .fitted, colour = "Fitted")) +
  labs(y = "Time",
       title = "log seasonal quadratic model") 

grid.arrange(p37,p38,p39,p40,p41,p42, nrow = 3, ncol = 2)
```
We can see that the log models appear to fit the data slightly better (some overshoot in the linear model around 1980s, whereas less in log linear model). Same with the quadratic models, appears like it's slightly overestimating in the quadratic model and is overestimating less (ie. in the middle of the seasonal variation) in the log quad model. We can see this in the seasonal model too. Moving forward with working on the log(co2) data with this data transformation we have a more stationarity of the residuals as well. 



```{r, message=FALSE, echo=FALSE,  fig.width=3, fig.height=2}
#plot model residuals 
#might need to delete

lin_resid <- log_lin_model %>% gg_tsresiduals()+labs(title = "linear model")
lin_resid
quad_resid<- log_quad_model %>% gg_tsresiduals()+labs(title = "log quadratic model")
quad_resid
sea_resid<-log_quadratic_season %>% gg_tsresiduals()+labs(title = "log quad seasonal model")
sea_resid

mod1_resi <- ggplot(aes(x=lin_model$fitted.values, y=lin_model$residuals), data = lin_model)+ geom_point()+geom_smooth(se=FALSE)+labs(title = "linear model")

```


## Model Forecast

We chose the quadratic seasonal model to make prediction forecast of CO2 up to year 2020.

```{r predict 2020,  warnings = FALSE, echo = FALSE, fig.width=5.25, fig.height=3.5}
#generate predictions for up until 2020
# there are 23 years from Dec 1997 to Jan 2020 --> 276 months we need to predict for
predictions <- quadratic_season %>%
  fabletools::forecast(h=276)%>%
  autoplot(co2_ts)

predictions
```


## ARIMA Models 

We will also generate a few ARIMA models and compare them to our linear model. To select our ARIMA model we use the AIC, the AIC selects against models with too many parameters. We know that there is a seasonal component to our data, so we will also select for seasonal AR and MA values and check if seasonal differencing will make the data stationary. I am choosing to use the ARIMA() function to select our data. This method will determine the optimal p,d,q,P,D,Q values as well as the optimal levels of differencing for us to have stationary data and will then select a model based on the metric we have chosen as our criteria (AIC). We can interpret the resulting ARIMA model in terms of the number of (seasonal) AR terms, the level of differencing to acheive stationary data. We are including seasonality in our model because we can see in the decomposition as well as the time series plots that there is a strong possibility of a seasonal component in the CO2 levels. If adding a seasonal component improves the AIC score then such a model will be chosen.

```{r, echo = FALSE}
#takes a while, try to avoid re-running
#returns ARIMA(1,0,1)(4,1,0)[12] w/ drift

#including the constant because our data does not have a mean of 0 (even if we were to remove the trend)
#model.fit<-co2_ts %>%
#  model(fable::ARIMA(co2_val ~ 1 + pdq(0:10,0:2,0:10) + PDQ(0:10,0:2,0:10), ic="aic", stepwise=F, greedy=F))

#model.fit %>%
#  report()

#model.fit %>%
#  augment() %>%
#  ACF(.resid) %>%
#  autoplot()+
#  labs(title = "ACF plot of ARIMA(1,0,1)(4,1,0)[12] model residuals")

model.fit2<-co2_ts %>%
  model(ts.model=ARIMA(co2_val~1+pdq(1,0,1)+PDQ(4,1,0),ic="aic",greedy=F,stepwise=F))

model.fit2$ts.model

model.fit2 %>% coef()

```


With the AIC as our selection criteria we have estimated the model to be an ARIMA(1,0,1)(4,1,0)[12] with drift. This model has an AIC of 218, since this was the model that was chosen, this must be the smallest AIC value in the models that we have compared. This ARIMA(1,0,1)(4,1,0)[12] model can be interpreted by saying that there is 1 AR term, 1 MA term, 4 seasonal AR terms and the data had to be seasonally differenced once to be made stationary. the [12] at the end of the model also indicates


To be thorough we will also repeat the above process but instead using BIC and AICC as our selection metrics. In general the BIC is stricter than the AIC in penalizing additional parameters in our model, so it is possible that this selection process will result in a different model. When we repeated the above process using the bic or the aicc as our criteria, we found that we were still selecting the exact same ARIMA model, so we will move forwards with this model. 


## Forecasting Atmospheric CO2 Growth 

Now that we have a few different models that do a decent job at modeling our CO2 data, we want to use these models to generate predictions for us. 

### When will we reach 420 and 500 ppm CO2?
First we want to see when these models forecast that the atmospheric CO2 levels will reach 420ppm and 500ppm. Since we know there is a overall upwards trend as well as a seasonal component to the CO2 levels, when we generate these predictions we will actually want to look at both the first and the last times that the model predicts the atmospheric CO2 levels to be at these values. We know from our previous predictions for the linear model that even by 2020, the predicted CO2 ppm is not 420 ppm. Of course, there may be some variance in the predictions between the ARIMA and linear model but this does serve as a good guideline. 

When we do this we can then filter our predictions to find the times when the CO2 levels are predicted to be 420 and 500ppm. We should note that these are approximations as the true predictions from our model are not integers and instead are the mean of a prediction distribution. As a result we had to round these prediction values to find where the predicted CO2 will reach these levels. 

Our ARIMA model predicts that the first time that the atmospheric CO2 levels will to be 420ppm is April 2038, and the last time is October 2042. To be more accurate, we found that the predicted CO2 values will reach 420ppm for the first time sometime in between March 2038 and April 2038 and for the last time sometime in between September 2042 and October 2042.  We can also see that the first time that the atmospheric CO2 levels are predicted to be 500ppm is March 2101, and the last time is October 2105 Again, to be more accurate, we found that the predicted CO2 values will reach 500ppm for the first time sometime in between March 2101 and April 2101 and the for the last time sometime in between October 2105 and November 2105. 

### What do we predict CO2 levels will be in 2100 (103 years from now)?
We also want to look at the predictions for our models for the more distant future. Here we will look at what the model predicts will be the CO2 levels in the year 2100. Plot on the left is model prediction of linear quadratic seasonal and on the right is the ARIMA model. The linear quadratic seasonal predicts for a steeper increase of the CO2 level up to year 2100 compared to the ARIMA model. 
```{r, echo=FALSE,  fig.width=5.25, fig.height=3.5}
predictions_ARIMA3 <- model.fit2  %>%
  fabletools::forecast(h=1236)%>%
  autoplot(co2_ts)

predictions_qs <- quadratic_season %>%
  fabletools::forecast(h=1236)%>%
  autoplot(co2_ts)

predictions_qs | predictions_ARIMA3 
```
# Report from the Point of View of the Present 

One of the very interesting features of Keeling and colleagues' research is that they were able to evaluate, and re-evaluate the data as new series of measurements were released. 

## Introduction 

Now there are more dataset that we can collect and up to present on the modern CO2 emission data. We will evaluate our previous data prediction model to the actual measure on newly collect data from United States' National Oceanic and Atmospheric Administration.

```{r, echo = FALSE }
co2_new <- read.csv("./co2_weekly_mlo.csv", header = TRUE, skip = 51)
co2_new <- co2_new[1:6]

co2_present<- co2_new %>%
  mutate(time_index = as.Date(make_datetime(year, month, day))) %>%
  mutate(month_index = yearmonth(time_index)) %>%
  tsibble::as_tsibble(index = month_index, key = time_index) %>%
  filter(ndays != 0) %>%
  filter(year > 1997) %>%
  index_by(date = month_index)%>%
  dplyr::summarise(co2_avg = mean(average))

colnames(co2_present)[1] = "time_index"
colnames(co2_present)[2] = "average"

tail(co2_present)
```


```{r,  echo = FALSE }
timeplot <- co2_present %>%
  ggplot() + 
  aes(x=time_index, y=average) + 
  geom_line(color = 'steelblue') +
  labs(
    title = TeX(r'(Mean $CO_2$ from 1997 to Present)'),
    subtitle = 'weekly data',
    x = 'Date',
    y = TeX(r'($CO_2$ parts per million)')
  )

hist <- co2_present %>% 
  ggplot()+
  geom_histogram(aes(x= average), binwidth = 0.5) + 
  labs( title = 'Histogram of CO2 levels', x = 'CO2')

acf <- ggAcf(co2_present$average, type = 'correlation') + labs(title = 'ACF of CO2 Levels')
pacf <-ggAcf(co2_present$average, type = 'partial') + labs(title = 'PACF of CO2 Levels')

(timeplot + hist) / (acf + pacf)
```

## Compare linear and Arima model forecasts against realized CO2


```{r, echo = FALSE}
prediction_lin <- quadratic_season %>%
  fabletools::forecast(h=302)

prediction_arima <- model.fit2 %>%
  fabletools::forecast(h=302)

p_compare <- ggplot() +
  geom_line(aes(x = prediction_lin$index, y = prediction_lin$.mean, colour = "Quadratic Seasonal Linear Model")) +
  geom_line(aes(x = prediction_arima$index, y = prediction_arima$.mean, colour = "Arima Model")) +
  geom_line(aes(x = co2_present$time_index, y = co2_present$average, colour = 'Actual')) + 
  labs(x = "Date", y = 'CO2 levels (ppm)',
       title = "Previous Model Predictions vs Actual Data for 1998-2023", 
       color = '') 

p_compare
```


The linear model is a fairly close match to the actual values, it doe seem like from 200-2005 it has a tendency to slightly overestimate the CO2 levels, and then from 2015 to 2020 it appears to slightly underestimate the CO2 levels. 

The ARIMA model  deviates from the actual values. The model values are similar until 2000, though the model does tend to underestimate the CO2 levels even during this time period. The model really deviates from the actual values at around 2003, as it starts to severely underestimate the CO2 levels. It appears that the keeling curve has shown some acceleration in the increase of the mean over time, and this might explain the increasing gap between the ARIMA model performance and the true CO2 levels as we move away from 1997.


## Evaluate the performance of 1997 linear and ARIMA models 

In 1997 we predicted that the CO2 levels would cross 420ppm at around April 2038, but from the actual data we can see that the CO2 levels cross 420ppm by February 2022, which is an about a 15 year difference. This is in-line with what we observed in our ARIMA model predictions as the  ARIMA model was underestimating the CO2 levels in comparison to the actual CO2 levels.
````{r, echo = FALSE}
#Filter for 420ppm with some tolerance since these are doubles
# cross 420 ppm by 2022 Feb
ppm420 <- co2_present %>% 
  as.data.frame()%>%
  filter((average <= 422) & (average >= 419) )
#ppm420

```

We can also assess the overall performance of our model using a test metric such as the RMSE. The RMSE is the root mean squared error and is a metric that captures on average how far our predictions are from the actual values. It is calculated with the formula $\sqrt{\sum_{i=1}^{N}\frac{(y_{i}-\hat{y}_i)}{N}}$ where N is the number of observations, $y_i$ is the ith actual CO2 value and $\hat{y}_i$ is the ith CO2 prediction -- in essence we are squaring the sum of the differences between the actual and predicted values, and then dividing by the number of observations before taking the square root. When we calculate the RMSE for our two models of interest we can see that the ARIMA model performs worse than the quadratic seasonal model by an order of roughly 10. The Quadratic Seasonal model's RMSE is 0.79235, meaning that on average the Quadratic Seasonal model prediction is off by about 0.79235 ppm. By contrast the ARIMA model RMSE is 8.6259 meaning that on average the ARIMA model is off by acout 8.6259 ppm. 

```{r, echo = FALSE}
# Use RMSE as a formal test to evaluate the models 

# Calculate the RMSE
rmse_lin <- sqrt(mean((prediction_lin$.mean - co2_present$average)^2))
rmse_arima <- sqrt(mean((prediction_arima$.mean - co2_present$average)^2))

# Print the result
print(cat("Quadratic Seasonal Model RMSE =", rmse_lin))
print(cat("ARIMA model RMSE =", rmse_arima))
```


## Train best models on present data

Seasonally adjust the weekly NOAA data, and split both seasonally-adjusted (SA) and non-seasonally-adjusted (NSA) series into training and test sets, using the last two years of observations as the test sets. For both SA and NSA series, fit ARIMA models using all appropriate steps. Measure and discuss how your models perform in-sample and (psuedo-) out-of-sample, comparing candidate models and explaining your choice. In addition, fit a polynomial time-trend model to the seasonally-adjusted series and compare its performance to that of your ARIMA model.

```{r, warnings = FALSE, echo = FALSE}
# Seasonally adjust the data
co2_present_sa <- setNames(aggregate(co2_present$average, by=list(year(co2_present$time_index)), mean), 
                      c("year", "yr_co2"))
co2_present_nsa <- co2_present
  
  #setNames(aggregate(co2_present$average, by=list(co2_present$time_index), mean), 
                     # c("by_month", "tot_CO2"))


#Split into training and test
co2_train_sa <- co2_present_sa %>% filter(year <= max(year)-2) %>% as_tsibble(index = year)
co2_test_sa <- co2_present_sa %>% filter(year > max(year)-2)  %>% as_tsibble(index = year)


co2_train_nsa <- co2_present_nsa %>% 
  as_tsibble(index=time_index) %>% filter(year(time_index) <= max(year(time_index))-2) 
co2_test_nsa <- co2_present_nsa %>% 
  as_tsibble(index=time_index) %>% filter(year(time_index) > max(year(time_index))-2) 

#Fit the seasonally adjusted model
sa.model.fit <-co2_train_sa %>%
  model(fable::ARIMA(yr_co2 ~ 1 + pdq(0:10,0:2,0:10) + PDQ(0:10,0:2,0:10), ic="aic", stepwise=F, greedy=F))

sa.model.graph <- augment(sa.model.fit)%>%
  ggplot(aes(x = year)) +
  geom_line(aes(y = yr_co2, colour = "Data")) +
  geom_line(aes(y = .fitted, colour = "Fitted")) +
  labs(y = "Time",
       title = "Seasonally Adjusted Model") 


#Fit the non-seasonally adjusted model
nsa.model.fit <-co2_train_nsa %>%
  model(fable::ARIMA(average ~ 1 + pdq(0:10,0:2,0:10) + PDQ(0:10,0:2,0:10), ic="aic", stepwise=F, greedy=F))

nsa.model.graph <- augment(nsa.model.fit)%>%
  ggplot(aes(x = time_index)) +
  geom_line(aes(y = average, colour = "Data")) +
  geom_line(aes(y = .fitted, colour = "Fitted")) +
  labs(y = "Time",
       title = "Non-Seasonally Adjusted Model") 


sa.model.graph |  nsa.model.graph

#model.fit %>%
#  report()

#model.fit %>%
#  augment() %>%
#  ACF(.resid) %>%
#  autoplot()+
#  labs(title = "ACF plot of ARIMA(1,0,1)(4,1,0)[12] model residuals")
```

```{r, echo = FALSE,  fig.width=5.25, fig.height=3.5}
#Seasonally adjusted model predictions
sa_prediction <- sa.model.fit %>%
  fabletools::forecast(h=2, level = 0.95) %>%
  autoplot() +
  geom_line(aes(x = co2_test_sa$year, y = co2_test_sa$yr_co2, colour = 'Actual')) + 
  labs(x = "Time", y = 'CO2 levels',
       title = "Seasonally Adjusted Model (ARIMA) Prediction vs Actual") 

#Non-seasonally adjusted model predictions
nsa_prediction <- nsa.model.fit %>%
  fabletools::forecast(h=14, level = 0.95) %>%
  autoplot() +
  geom_line(aes(x = co2_test_nsa$time_index, y = co2_test_nsa$average, colour = 'Actual')) + 
  labs(x = "Time", y = 'CO2 levels',
       title = "Non Seasonally Adjusted Model (ARIMA) Prediction vs Actual") 

#Non-seasonally adjusted model predictions
quad_sa <- co2_train_sa%>%  model(trend_model = TSLM(yr_co2 ~ trend() + I(trend()^2 )))

quad_predictions <- quad_sa %>%
  fabletools::forecast(h=2)%>%
  autoplot(co2_test_sa) + labs(x = "Time", y = 'CO2 levels',
       title = "Seasonally Adjusted Model (Quad) Prediction vs Actual") 

sa_prediction / quad_predictions /  nsa_prediction 


```

Both seasonally adjusted and non-seasonally adjust models perform well. The data fits perfectly within the training dataset. with forecasts, the seasonally adjust model falls short, deviating from the actual model. The non-seasonally adjusted ARIMA model predicts close to what the actual values were.The quadratic model performs the worst compared to the ARIMA model when using Seasonally Adjusted models.

## How bad could it get?

With the non-seasonally adjusted data series, generate predictions for when atmospheric CO2 is expected to be at 420 ppm and 500 ppm levels for the first and final times (consider prediction intervals as well as point estimates in your answer). Generate a prediction for atmospheric CO2 levels in the year 2122. How confident are you that these will be accurate predictions?

```{r ,  warnings = FALSE, echo = FALSE,  fig.width=5.25, fig.height=3.5}
co2_present_prediction <- nsa.model.fit %>%
  fabletools::forecast(h=1212)
  
co2_present_pred_graph <- co2_present_prediction %>%  
  autoplot() + geom_hline(aes(yintercept = 420, color = "420ppm"), linetype = "dashed")+
  geom_hline(aes(yintercept = 500, color = "500ppm"), linetype = "dashed")+
  labs(title = "Predictions for Co2 levels 1998-2122", 
       color = " ")+
  ylab("Prediction CO2 Level (ppm)")+
  xlab("Date")

#display 5 digits (in this case 2 decimal points)
options(digits = 5)

#Filter for 420ppm with some tolerance since these are doubles
ppm420 <- co2_present_prediction %>% 
  as.data.frame()%>%
  filter((.mean <= 422) & (.mean >= 419) )
#ppm420

#Filter for 500ppm with some tolerance since these are doubles
ppm500 <- co2_present_prediction %>% 
  as.data.frame()%>%
  filter((.mean <= 503) & (.mean >= 497) )
#ppm500

co2_present_pred_graph
```

```{r, echo = FALSE}

co2_2122 <- co2_present_prediction %>% filter(year(time_index) == 2122)
mean(co2_2122$.mean)

```
It's predicted that the average co2 level in 2122 would be 637.42 ppm. There's a possibility that the actual values are worse than predicted judging from the predictions in the Keeling curve. If there's no mitigation in the co2 levels in the future, the co2 levels won't likely decline.

# Conclusions 

We have conducted a CO2 prediction modeling though two sets of data set. Initially, we have generated the prediction from Keeling's data set to predict CO2 emission. Data transition was explored examining log and seasonal transition. We have also conducted linear, quadradic linear and ARIMA models to compare the prediction behavior of the models. Ultimately evaluating the model with the up to present data of CO2 emission data we were able to confirm that the non-seasonally adjusted ARIMA model had the model of best prediction. 